# 0026 – Verificare: ce este în neregulă cu scraping-ul prețurilor CEA și EUA

## Rezumat

Scraping-ul pentru CEA și EUA eșuează cu mesajul **"Rate limited by source. Please wait a few minutes before retrying."** din două motive principale: (1) sursa carboncredits.com aplică rate limiting (HTTP 429 sau mesaj similar), și (2) **arhitectura actuală face două request-uri la același endpoint** (unul per sursă) în loc de unul singur, dublând volumul de request-uri și mărind probabilitatea de rate limit.

---

## 1. Ce se întâmplă acum

### Fluxul de scraping pentru carboncredits.com

- Ambele surse (EUA și CEA) au URL-ul `https://carboncredits.com/carbon-prices-today/`.
- În `price_scraper.py`, orice URL care conține `"carboncredits.com"` este tratat special și se apelează `_scrape_carboncredits(source)`.
- `_scrape_carboncredits(source)` face **un request HTTP** la același endpoint pentru **fiecare** sursă:
  - `api_url = "https://carboncredits.com/wp-content/themes/fetchcarbonprices.php"`
  - Pentru sursa EUA → `client.get(api_url)` → parse răspuns, extrage doar prețul EU.
  - Pentru sursa CEA → `client.get(api_url)` → parse răspuns, extrage doar prețul China.

Deci la fiecare ciclu de refresh (manual sau din scheduler) se execută **două request-uri identice** la același PHP, în loc de unul singur.

### Unde se face „dublarea”

| Locus | Fișier | Comportament |
|-------|--------|--------------|
| Test / Refresh per sursă | `backend/app/api/v1/admin.py` | `test_scraping_source` / `refresh_scraping_source` apelează `price_scraper.scrape_source(source)` respectiv `refresh_source(source, db)` **per source_id**. Două surse (EUA + CEA) = două request-uri. |
| Scheduler | `backend/app/main.py` | `price_scraping_scheduler_loop()` parcurge toate sursele active și pentru fiecare sursă „due” apelează `price_scraper.refresh_source(source, db)`. EUA și CEA au același interval → ambele due în același ciclu → două request-uri la fetchcarbonprices.php. |
| Scraper per sursă | `backend/app/services/price_scraper.py` | `scrape_source()` → `_scrape_carboncredits(source)` face un `client.get(api_url)` și parsează răspunsul doar pentru `source.certificate_type` (EUA sau CEA). Nu există niciun „fetch comun” care să obțină o dată CSV-ul și să actualizeze ambele tipuri. |

### De unde vine mesajul „Rate limited by source”

- Când carboncredits.com răspunde cu **HTTP 429** sau excepția conține „429”, „rate limit” sau „too many requests”, backend-ul mapează excepția la un mesaj prietenos:
- Fișier: `backend/app/api/v1/admin.py`, funcția `_scraping_error_status()` (linii ~1472–1481). Returnează `(429, "Rate limited by source. Please wait a few minutes before retrying.")`.
- Frontend: în `SettingsPage.tsx`, la refresh/test eșuat se folosește `getApiErrorMessage(e)` și se pune în `error` → se afișează în `AlertBanner` (variantă error).

Deci **simptomul** (mesajul roșu și status Failed) este corect; **cauza** este rate limiting de la sursă, agravată de faptul că trimitem de două ori mai multe request-uri decât e necesar.

---

## 2. Probleme identificate (în ordine)

1. **Rate limiting de la carboncredits.com**  
   Sursa externă limitează numărul de request-uri. Request-urile noastre (în special două la același endpoint în scurt timp) cresc șansa de a atinge acest limit.

2. **Două request-uri la același endpoint**  
   API-ul `fetchcarbonprices.php` returnează **toate** piețele într-un singur răspuns CSV (EU, China etc.). Ar trebui să facem **un singur** request per „ciclu” și din acel răspuns să actualizăm atât sursa EUA cât și sursa CEA. Astfel se înjumătățește numărul de request-uri către carboncredits.com și se reduce probabilitatea de rate limit.

3. **Lipsă tratare 429 în scraper**  
   În `_scrape_carboncredits()` (și în `scrape_with_httpx`), la `response.status_code != 200` se aruncă doar `Exception(f"HTTP {response.status_code}")`. Nu se verifică explicit 429 și nu se propune un mesaj sau logică de „retry after”. Backend-ul detectează „429” în string-ul excepției în `_scraping_error_status`, deci utilizatorul vede mesajul corect, dar în scraper nu există nicio logică de backoff sau respectare a unui eventual header `Retry-After`.

4. **Scheduler fără backoff la eșec**  
   În `main.py`, la excepție în `refresh_source` se doar loghează și se continuă; la următoarea iterație (după 60 s) se reîncearcă pentru toate sursele „due”. Nu există backoff (ex. să nu reîncerce sursele carboncredits.com pentru N minute după 429), ceea ce poate menține un flux constant de request-uri eșuate și poate înrăutăți rate limiting.

---

## 3. Fișiere și funcții relevante

| Scop | Fișier | Funcții / zone |
|------|--------|-----------------|
| Detectare rate limit și mesaj utilizator | `backend/app/api/v1/admin.py` | `_scraping_error_status()`, `test_scraping_source`, `refresh_scraping_source` |
| Scraping carboncredits.com (1 request per sursă) | `backend/app/services/price_scraper.py` | `scrape_source()`, `_scrape_carboncredits()`, `refresh_source()` |
| Scheduler care apelează refresh per sursă | `backend/app/main.py` | `price_scraping_scheduler_loop()` |
| Afișare eroare | `frontend/src/pages/SettingsPage.tsx` | `error`, `AlertBanner`, handlers pentru test/refresh |

---

## 4. Direcții de remediere (fără cod)

- **Fetch comun pentru carboncredits.com**  
  Introducerea unei funcții (sau extensie a logicii existente) care:
  - face **un singur** GET la `fetchcarbonprices.php`;
  - parsează CSV-ul și extrage prețurile pentru EU și China;
  - actualizează în DB toate sursele active de tip carboncredits.com (EUA și CEA) din acest răspuns, în loc să apeleze `refresh_source()` separat pentru fiecare sursă.
  Scheduler-ul și endpoint-urile de refresh trebuie să recunoască „grupul” carboncredits.com și să declanșeze acest refresh comun (o dată per ciclu) în loc de N refresh-uri independente.

- **Scheduler**  
  În `price_scraping_scheduler_loop()`: pentru surse care folosesc carboncredits.com, să nu se mai apeleze `refresh_source(source, db)` per sursă, ci o singură operație „refresh all carboncredits.com” care face un request și actualizează ambele surse. Intervalul la care rulează acest refresh comun poate fi cel al celei mai frecvente surse (ex. min(interval_eua, interval_cea)) sau un interval configurat la nivel de „grup”.

- **Opțional: 429 și backoff**  
  În `price_scraper.py`, la răspuns 429 de la carboncredits.com (sau la orice sursă), fie să se arunce o excepție cu mesaj explicit „rate limit” (deja parțial acoperit prin „429” în string), fie să se citească header-ul `Retry-After` și să se expună pentru API/scheduler. Opțional, scheduler-ul sau un cache Redis poate stoca „skip carboncredits până la ora X” după un 429, ca să nu reîncerce imediat.

Acest plan se limitează la **verificarea cauzelor** și la **stabilirea remediilor tehnice**; nu include criterii de succes, timeline sau migrații de date.
